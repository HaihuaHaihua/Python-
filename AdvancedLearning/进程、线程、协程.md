## Python进程、线程、协程

### 线程

​	基于_thread的threading模块，提供了更加方便的api来处理进程

```python
import threading
import time

def worker(num):
    time.sleep(1)
    print("The num is %d" %num)
    return

for i in range(20):
    t = threading.Thread(target=worker,args=(i,),name="t.%d"%i)
    t.start()
```

### 线程锁

​	`threading.RLock`允许在同一线程中被多次acquire。而`threading.Lock`却不允许这种情况，只能单对使用。 如果使用RLock，那么acquire和release必须成对出现，即调用了n次acquire，必须调用n次的release才能真正释放所占用的琐。

```python
import threading
import time

def test_rlock():
    globals_num = 0
    rlock = threading.RLock()
    # lock = threading.Lock()
    for i in range(10):
        t = threading.Thread(target=test_func,args=(i,rlock,globals_num,),name="t.%d"%i)
        t.start()

def test_func(num,lock,globals_num):
    lock.acquire()
    globals_num += 1
    time.sleep(1)
    print("This thread is %d"%num)
    print("globals_num:",globals_num)
    lock.release()

if __name__ == "__main__":
    test_lock()
```

### 线程事件

​	事件处理的机制：全局定义了一个“Flag”，如果“Flag”值为 False，那么当程序执行 event.wait 方法时就会阻塞，如果“Flag”值为True，那么event.wait 方法时便不再阻塞。

​	事件提供了三个方法，`wait()`设置阻塞状态；`set()`设置`flag`为`True`；`clear`设置`flag`为`False`。

```python
def test_event():
    event = threading.Event()
    event2 = threading.Event()
    t = threading.Thread(name='t',target=do_event,args=(event,))
    t2 = threading.Thread(name='t2',target=do_event,args=(event2,))
    t.start()
    t2.start()
    print("They are waiting!")
    flag = True
    while flag:
        inp = input("The thread that you want to unlock and input 'exit' to exit : ")
        if inp=='t':
            event.set()
            print("You have unlocked 't' ")
        elif inp == 't2':
            event2.set()
            print("You have unlocked 't2' ")
        elif inp == 'exit':
            break

def do_event(event):
    print("start")
    event.wait()
    print("end")

if __name__ == "__main__":
    test_event()
```

### Condition类

​	Condition类实现了一个conditon变量。 这个conditiaon变量允许一个或多个线程等待，直到他们被另一个线程通知。

​	wati()释放锁以后，在被调用相同条件的另一个进程用notify() 或者 notify_all() 叫醒之前 会一直阻塞。如果有等待的线程，notify()方法会唤醒一个在等待conditon变量的线程。notify_all() 则会唤醒所有在等待conditon变量的线程。

```python
def consumer(cond):
    with cond:
        print("consumer before wait")
        cond.wait()
        print("consumer after wait")
   
def producer(cond):
    with cond:
        print("producer before notifyAll")
        cond.notifyAll() #唤醒所有在等待condition变量的线程
        #cond.notify() #唤醒一个在等待condition变量的线程
        print("producer after notifyAll")
   
def test_condition():
    condition = threading.Condition()
    c1 = threading.Thread(name="c1", target=consumer, args=(condition,))
    c2 = threading.Thread(name="c2", target=consumer, args=(condition,))
    
    p = threading.Thread(name="p", target=producer, args=(condition,))
    
    c1.start()
    time.sleep(2)
    c2.start()
    time.sleep(2)
    p.start()
if __name__ == "__main__":
    test_condition()
```

### 进程

​	在multiprocessing中，通过创建Process对象生成进程，然后调用它的start()方法激活进程

```python
from multiprocessing import Process

def create_process():
    p = Process(target=hello,args=("Haihua",))
    p1 = Process(target=hello,args=("WangHaihua",))
    p.start()
    p1.start()
    # p.join() 逐个执行进程 使得不并发

def hello(name):
    print("hello, ",name)

if __name__ == "__main__":
    create_process()
```

​	在使用并发设计的时候最好尽可能的避免共享数据，但是在特殊情况下`multiprocessing`提供了`Value`和`Array`两种方式将数据存储在一个共享内存地图中

```python
from multiprocessing import Array,Value

def process_share():
    num = Value('d',1.1) #第一个参数 'd'表示数据类型 为double
    arr = Array('i',range(11)) #第一个参数 'i'表示数据类型 为整型
    display_sharedata(num,arr)
    a = Process(target = changedata,args=(num,arr) )
    b = Process(target = changedata,args=(num,arr) )
    #使用多进程的常规方法是，先依次调用start启动进程，再依次调用join要求主进程等待子进程的结束
    a.start()
    b.start()
    a.join() #join是用来阻塞当前线程的
    display_sharedata(num,arr)
    b.join()
    display_sharedata(num,arr)
    
def changedata(num,arr):
    num.value = 0.0
    for i in range(len(arr)):
        arr[i] += 1         

def display_sharedata(num,arr):
    print("the value : ",num.value)
    print("the array : ",end='')
    for i in arr:
        print(i,end=' ')
    print()


if __name__ == "__main__":
    process_share()
```

​	另外multiprocessing模块也提供了更为强大的Manager来实现进程间数据共享，由Manager()返回的manager提供list, dict, Namespace, Lock, RLock, Semaphore, BoundedSemaphore, Condition, Event, Barrier, Queue, Value and Array类型的支持

```python
from multiprocessing import Manager

def f(d,l):
    d["name"] = "zhangyanlin"
    d["age"] = 18
    d["Job"] = "pythoner"
    l.reverse()
  
def process_manager():
    with Manager() as man:
        d = man.dict()
        l = man.list(range(10))
  
        p = Process(target=f,args=(d,l))
        p.start()
        p.join()
  
        print(d)
        print(l)

if __name__ == "__main__":
    process_manager()
```

### 进程池

​	Pool类描述了一个工作进程池，进程池内部维护一个进程序列，当使用时，则去进程池中获取一个进程，如果进程池序列中没有可供使用的进进程，那么程序就会等待，直到进程池中有可用进程为止。

​	Pool构造方法的几个参数

* processes ：使用的工作进程的数量，如果processes是None那么使用 os.cpu_count()返回的数量。

* initializer： 如果initializer是None，那么每一个工作进程在开始的时候会调用initializer(*initargs)。

* maxtasksperchild：工作进程退出之前可以完成的任务数，完成后用一个心的工作进程来替代原进程，来让闲置的资源被释放。maxtasksperchild默认是None，意味着只要Pool存在工作进程就会一直存活。

* context: 用在制定工作进程启动时的上下文，一般使用 multiprocessing.Pool() 或者一个context对象的Pool()方法来创建一个池，两种方法都适当的设置了context

​	Pool类的几个方法

* apply(func[, args[, kwds]]) ：使用arg和kwds参数调用func函数，结果返回前会一直阻塞，由于这个原因，apply_async()更适合并发执行，另外，func函数仅被pool中的一个进程运行
* apply_async(func[, args[, kwds[, callback[, error_callback]]]]) ： apply()方法的一个变体，会返回一个结果对象。如果callback被指定，那么callback可以接收一个参数然后被调用，当结果准备好回调时会调用callback，调用失败时，则用error_callback替换callback。 Callbacks应被立即完成，否则处理结果的线程会被阻塞。
* close() ： 阻止更多的任务提交到pool，待任务完成后，工作进程会退出。
* terminate() ： 不管任务是否完成，立即停止工作进程。在对pool对象进程垃圾回收的时候，会立即调用terminate()。
* join() : wait工作线程的退出，在调用join()前，必须调用close() or terminate()。这样是因为被终止的进程需要被父进程调用wait（join等价与wait），否则进程会成为僵尸进程。

```python
from multiprocessing import Pool
import time

def func_apply(i):
    time.sleep(1)
    print("I recieved %d"%i)
    return i + 100

def pool_apply():
    pool = Pool(5)
    for i in range(1,20):
        pool.apply(func=func_apply,args=(i,))
    pool.close()
    pool.join()     
        
def func_callback(arg):
    print("the arg is %d"%arg)
    
def pool_apply_async():
    pool = Pool(5)
    for i in range(1,20):
        pool.apply_async(func=func_apply,args=(i,),callback=func_callback)
   	pool.close()
    pool.join()
    
if __name__=="__main__":
    pool_apply()
    # pool_apply_async()
```

### 协程

​	线程和进程的操作是由程序触发系统接口，最后的执行者是系统；`event loop`协程的操作则是程序员。协程存在的意义：对于多线程应用，CPU通过切片的方式来切换线程间的执行，线程切换时需要耗时（保存状态，下次继续）。协程，则只使用一个线程，在一个线程中规定某个代码块执行顺序。(协程的适用场景：当程序中存在大量不需要CPU的操作时（IO），适用于协程；)

​	协程的特性：

* 注册、执行、取消延时调用(异步函数)

* 创建用于通信的client和server协议(工具)

* 创建和别的程序通信的子进程和协议(工具)

* 把函数调用送入线程池中

​	协程的使用：

* asyncio.get_event_loop()  : asyncio启动默认的event loop
* run_until_complete()  :  这个函数是阻塞执行的，知道所有的异步函数执行完成
* close()  :  关闭event loop

​	协程的第三方库：`gevent`

```python
import asyncio
   
async def cor1():
    print("COR1 start")
    await cor2()
    print("COR1 end")
   
async def cor2():
    print("COR2")
   
loop = asyncio.get_event_loop()
loop.run_until_complete(cor1())
loop.close()
```

[参考文献](<https://www.pythontab.com/html/2016/pythonhexinbiancheng_0724/1053.html>)

